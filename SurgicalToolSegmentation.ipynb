{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the required packages and library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the surgical tool images to fit to the Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(ImagePath, Width, Height):\n",
    "    img = cv2.imread(ImagePath, 1)\n",
    "    img = cv2.resize(img, ( Width , Height ))\n",
    "    img = img.astype(np.float32)\n",
    "    img[:,:,0] -= 103.939\n",
    "    img[:,:,1] -= 116.779\n",
    "    img[:,:,2] -= 123.68\n",
    "    img = np.rollaxis(img, 2, 0)\n",
    "    return img\n",
    "\n",
    "# def getImage(ImagePath, Width, Height):\n",
    "#     img = cv2.imread(ImagePath, 1)\n",
    "#     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#     h,s,v=cv2.split(img_hsv)\n",
    "#     ret,th = cv2.threshold(s,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "#     img=cv2.merge((img_gray,th,v))\n",
    "#     img = np.float32(cv2.resize(img, ( Width , Height ))) / 127.5 - 1\n",
    "#     img = np.rollaxis(img, 2, 0)\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the segmentation Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSegmentationMask(SegImagePath, numberClass,  Width, Height):\n",
    "    seg_labels = np.zeros((Height, Width, numberClass))\n",
    "    img = cv2.imread(SegImagePath, 1)\n",
    "    img = cv2.resize(img, ( Width, Height))\n",
    "    img = img[:, :, 0]\n",
    "    img = img/img.max()\n",
    "\n",
    "    for class_label in range(numberClass):\n",
    "        seg_labels[:, :, class_label] = (img == class_label ).astype(int)\n",
    "    seg_labels = np.reshape(seg_labels, ( Width*Height , numberClass))\n",
    "    return seg_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generator for the fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Generator(ImagesPath, SegImagePath, batch_size, numberClass, Height, Width):\n",
    "    assert ImagesPath[-1] == '/' # Image Path should be ended with /.\n",
    "    assert SegImagePath[-1] == '/' # Image Path should be ended with /.\n",
    "    \n",
    "    images = glob.glob(ImagesPath+\"*.jpg\")+glob.glob(ImagesPath+\"*.png\")+glob.glob(ImagesPath+\"*.jpeg\")\n",
    "    images.sort() # Sort the images \n",
    "    \n",
    "    mask  = glob.glob(SegImagePath+\"*.jpg\")+glob.glob(SegImagePath+\"*.png\")+glob.glob(SegImagePath+\"*.jpeg\")\n",
    "    mask.sort() # Sort the images\n",
    "    \n",
    "    # Total Number of images should be same as the total number of segmented Mask\n",
    "    assert len(images) == len(mask) \n",
    "\n",
    "    \n",
    "    # Checking that every image has their corresponding segmented mask.\n",
    "    for im , seg in zip(images,mask):\n",
    "        assert(  im.split('/')[-1].split(\".\")[0] ==  seg.split('/')[-1].split(\".\")[0] )\n",
    "    \n",
    "    zipped = itertools.cycle( zip(images,mask) )\n",
    "        \n",
    "    while True:\n",
    "        ImageArray = []\n",
    "        TargetArray = []\n",
    "        for _ in range( batch_size) :\n",
    "            im , seg = next(zipped)\n",
    "            ImageArray.append(getImage(im, Width, Height))\n",
    "            TargetArray.append(getSegmentationMask(seg, numberClass, 224, 224))\n",
    "            yield np.array(ImageArray), np.array(TargetArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Train and Test image Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentDirectory=os.getcwd()\n",
    "TrainImagePath=CurrentDirectory+'/FINAL/TrainImage/'\n",
    "TrainSegImagePath=CurrentDirectory+'/FINAL/TrainGT/'\n",
    "TestImagePath=CurrentDirectory+'/FINAL/TestImage/'\n",
    "TestSegImagePath=CurrentDirectory+'/FINAL/TestGT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_Weights_path = CurrentDirectory+\"/vgg16_weights_th_dim_ordering_th_kernels.h5\"\n",
    "# https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5\n",
    "\n",
    "IMAGE_ORDERING = 'channels_first'\n",
    "\n",
    "\n",
    "def VGGUnet(n_classes, input_height=224, input_width=224 ,vgg_level=3):\n",
    "    \n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "    \n",
    "    img_input = Input(shape=(3,input_height,input_width))\n",
    "    \n",
    "    # Block_1 of the VGG16\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block_2 of the VGG16\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "    \n",
    "    # Block_3 of the VGG16\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f3 = x\n",
    "    \n",
    "    # Block_4 of the VGG16\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f4 = x\n",
    "    \n",
    "    \n",
    "    # Block_5 of the VGG16\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f5 = x\n",
    "    \n",
    "    \n",
    "    #Fully Connected Layer of the VGG16\\\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense( 1000 , activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #Create VGG16 Model to fit the weight\n",
    "    vgg  = Model( img_input, x)\n",
    "    vgg.load_weights(VGG_Weights_path)\n",
    "#     levels = [f1 , f2 , f3 , f4 , f5 ]\n",
    "    \n",
    "    o = f4\n",
    "#     o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( ZeroPadding2D( (1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([ o ,f3],axis=1 )  )\n",
    "    o = ( ZeroPadding2D( (1,1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( Conv2D( 256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([o,f2],axis=1 ) )\n",
    "    o = ( ZeroPadding2D((1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 128 , (3, 3), padding='valid' , data_format=IMAGE_ORDERING ) )(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([o,f1],axis=1 ) )\n",
    "    o = ( ZeroPadding2D((1,1)  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( ZeroPadding2D((1,1)  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o =  Conv2D( n_classes , (3, 3) , padding='same', data_format=IMAGE_ORDERING )( o )\n",
    "    o_shape = Model(img_input , o ).output_shape\n",
    "    \n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "    o = (Reshape((  n_classes , outputHeight*outputWidth   )))(o)\n",
    "    \n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model( img_input , o )\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set all the Hyper-paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberClass=2\n",
    "Height=224\n",
    "Width=224\n",
    "optimizer='adadelta'\n",
    "loss='categorical_crossentropy'\n",
    "metric=['acc']\n",
    "train_batch_size=16\n",
    "test_batch_size=11\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Imges and create Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainGen=Generator(TrainImagePath, TrainSegImagePath,  train_batch_size,  numberClass, Height, Width)\n",
    "numberTrainImages=len(glob.glob(TrainImagePath+\"*.jpg\")+glob.glob(TrainImagePath+\"*.png\")+glob.glob(TrainImagePath+\"*.jpeg\"))\n",
    "\n",
    "TestGen=Generator(TestImagePath, TestSegImagePath,  test_batch_size,  numberClass, Height, Width)\n",
    "numberTestImages=len(glob.glob(TestImagePath+\"*.jpg\")+glob.glob(TestImagePath+\"*.png\")+glob.glob(TestImagePath+\"*.jpeg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Early stopping of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I stopped training automagically with EarlyStopping after 10 consecutive epochs without improvement\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max',restore_best_weights=True)\n",
    "\n",
    "\n",
    "modelName='SavedModel/VGGUnetModel'\n",
    "SaveweightName= modelName+'.hdf5'\n",
    "SaveModelName=modelName+'.yaml'\n",
    "\n",
    "SavingbestModel = ModelCheckpoint(SaveweightName, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred,smooth=1):\n",
    "    y_true_f = K.flatten(y_true) \n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection+smooth) / (K.sum(y_true_f) + K.sum(y_pred_f)+smooth) \n",
    "\n",
    "def dice_coef_loss(y_true, y_pred): \n",
    "    return 1-dice_coef(y_true, y_pred) \n",
    "\n",
    "# model.compile(optimizer=optimizer, loss=dice_coef_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 64, 224, 224) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 64, 224, 224) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 64, 112, 112) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 112, 112 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 112, 112 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 128, 56, 56)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 256, 56, 56)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 256, 56, 56)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 256, 56, 56)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 256, 28, 28)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 512, 28, 28)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 512, 28, 28)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 512, 28, 28)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 512, 14, 14)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 512, 16, 16)  0           block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 14, 14)  2359808     zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 14, 14)  56          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 512, 28, 28)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768, 28, 28)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 768, 30, 30)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 28, 28)  1769728     zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 28, 28)  112         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 56, 56)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 384, 56, 56)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 384, 58, 58)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 56, 56)  442496      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 56, 56)  224         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 112, 112 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192, 112, 112 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 192, 114, 114 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 112, 112) 110656      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 112, 112) 448         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 224, 224) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 64, 226, 226) 0           up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 224, 224) 36928       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 224, 224) 896         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 224, 224)  1154        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 50176)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 50176, 2)     0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 50176, 2)     0           permute_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,357,770\n",
      "Trainable params: 12,356,902\n",
      "Non-trainable params: 868\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGGUnet(numberClass, input_height=Height, input_width=224)\n",
    "\n",
    "model.compile(loss=loss, optimizer= optimizer, metrics=metric)\n",
    "model.summary()\n",
    "model_yaml = model.to_yaml()\n",
    "with open(SaveModelName, \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# history=model.fit_generator(TrainGen,\n",
    "#                          steps_per_epoch= 10*(numberTrainImages//train_batch_size),\n",
    "#                          epochs=epochs,\n",
    "#                          verbose=1,\n",
    "#                          validation_data=TestGen,\n",
    "#                          validation_steps=numberTestImages//test_batch_size,\n",
    "#                          callbacks=[early_stopping,SavingbestModel]\n",
    "#                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Traing and Validation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ec267d62786a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
